import{_ as e,o as t,c as o,a}from"./app.ba574bda.js";const f=JSON.parse('{"title":"Interactive Visual Comparison of Upscaling Models","description":"","frontmatter":{},"headers":[{"level":3,"title":"Purpose","slug":"purpose","link":"#purpose","children":[]},{"level":3,"title":"Motivation","slug":"motivation","link":"#motivation","children":[]},{"level":3,"title":"Progress","slug":"progress","link":"#progress","children":[]}],"relativePath":"index.md"}'),s={name:"index.md"},r=a('<h1 id="interactive-visual-comparison-of-upscaling-models" tabindex="-1">Interactive Visual Comparison of Upscaling Models <a class="header-anchor" href="#interactive-visual-comparison-of-upscaling-models" aria-hidden="true">#</a></h1><h3 id="purpose" tabindex="-1">Purpose <a class="header-anchor" href="#purpose" aria-hidden="true">#</a></h3><p>Do you like to compare results for yourself what the best upscaling model would be for your own images? Then I believe you might have come to the right place \u{1F603}<br> I made this site not to tell you what the best upscaling model is for your use case, but to provide a way for you to visually compare different upscaling models yourself so that you can choose the model you like best to upscale your own images or videos. This is important since I believe that not only that these preferences can be subjective, but also because it often depends on the input of what upscaling model output I like best.</p><h3 id="motivation" tabindex="-1">Motivation <a class="header-anchor" href="#motivation" aria-hidden="true">#</a></h3><p>When Midjourney released (open beta) I tried it out, and was wondering how I could best upscale these images in case I wanted to use them for as a desktop background image, which they were too small for. This path led me to chaiNNer project, and with it the Upscale Wiki, which features a lot of different models. At first I just used the UltraSharp model, but then got courious of how it compares to the other models, and then how these models fare against each other. It was interesting to compare different outputs to find the one I liked the most. This led me to create this youtube video (in swiss german) <a href="https://youtu.be/gqqtxlwYi1Y" target="_blank" rel="noreferrer">Mit AI Bilder Vergr\xF6ssere</a> where I wanted to show people how to easily upscale such a generated image for free, then I created this youtube video <a href="https://youtu.be/0TYRDmQ5LZk" target="_blank" rel="noreferrer">ESRGAN Universal Models Visual Comparison</a> where I compared just the Universal Models category from the Upscale Wiki (corresponds to <a href="/upscale/multimodels.html#set-1">Set 1</a>), then I expanded that set and made a reddit post <a href="https://www.reddit.com/r/ArtificialInteligence/comments/yaxs13/image_upscaling_models_compared_general_photo_and/?utm_source=share&amp;utm_medium=web2x&amp;context=3" target="_blank" rel="noreferrer">Image Upscaling Models Compared (General, Photo and Faces)</a> (corresponds to <a href="/upscale/multimodels.html#set-2">Set 2</a>) and made another Art/Pixel Art set for another reddit post <a href="https://www.reddit.com/r/StableDiffusion/comments/yev37i/comparison_of_upscaling_models_for_ai_generated/" target="_blank" rel="noreferrer">Comparison of Upscaling Models for AI generated images</a> (corresponds to <a href="/upscale/multimodels.html#set-3">Set 3</a>) which led me to create this website to have it all in one place since I was going crazy in creating more sets/comparisons with <a href="/upscale/multimodels.html#set-4">Set 4</a> where I used every applicable model that was present on my laptop for the comparison slider.</p><h3 id="progress" tabindex="-1">Progress <a class="header-anchor" href="#progress" aria-hidden="true">#</a></h3><p>Since at that time I also got interested into video upscaling and made another youtube video about that (in swiss german again) <a href="https://youtu.be/6Vq14AY4CCQ" target="_blank" rel="noreferrer">Mit AI Videos vergr\xF6ssere</a> with examples at the end of the video, I thought I could do a section on here for videos too, but to decide on some input clips, generate output example clips and figure out in what way I want to present them will take me some time.</p>',7),i=[r];function n(l,d,h,c,p,u){return t(),o("div",null,i)}const g=e(s,[["render",n]]);export{f as __pageData,g as default};
